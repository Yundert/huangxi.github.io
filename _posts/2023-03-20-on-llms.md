---
id: 20230320
title: 生成式AI
pdate: "20 Mar 2023"
author: Xi
comments: false
layout: post
categories: Thoughts
tags: AIGC
guid: https://yundert.github.io/2023/03/20/on-chatgpt/
permalink: /2023/03/20/on-chatgpt/
abstract: 关于最近的LLMs。
---

| ![front image](/images/20220426fig1.png) |
|:--:|
| <b style="font-size:12px"> An example of teacher-student interaction for knowledge distillation (source from the Internet) </b>|


### 背景与动因

过去十余年，机器学习技术（尤其是深度学习）在数据、算法、算力三要素的协同促进下，掀起了新一波的人工智能热潮。近来，人工智能也从云端等坐拥充足资源的集中式计算环境，逐步下沉至异构边缘设备共生的网络边缘生态圈，与边缘计算、物联网、无人驾驶等技术融合，赋能不同垂直领域的业务场景，实现更精细的服务定制、质量管理、决策辅助及流程的降本增效。


这其中常见的核心问题之一，便是”如何实现已训练模型在生产环境下的部署”。其挑战源于训练与生产环境的差异。差异因素众多，机器学习要素之二——“领域”（domain）和“模型”（model）——便包含其中。


为了便于理解，我们以监督学习为例。监督学习中，“领域”刻画了学习任务的上下文，其包括任务所感兴趣的所有事件观察的集合，和定义其上的有效分布；而“模型”则刻画了这些事件观察中样本与标签之间的潜在关联。而学习的目标便是利用产生于给定“领域”的有限样本，还原出背后关联。


| ![front image](/images/20220426fig2.png) |
|:--:|
| <b style="font-size:12px"> (Source from the Internet) </b>|


相应地，模型迁移与部署过程中，同一监督学习任务在领域上的差异可产生于生产环境的复杂性（如实际场景更复杂，许多事件观察鲜见于训练环节）或事件分布的差异；对于模型差异，主要源头为部署时的资源限制，譬如实际设备难以满足模型推理的资源需求，使部署模型不得不有别于原模型。这两类差异的组合，衍化出了不同的技术范畴：1）当领域不同而模型相同时，关注点在如何完成从原领域到部署时目标领域的适配（domain adaption）；2）当领域不变而模型有差异，重点在“如何完成从训练模型到部署模型的转化”；3）更一般的情况（甚至任务有别时），则属于迁移学习（transfer learning）的范畴。本文关注第二类情况。


实现“训练模型到部署模型的转化”有两大常见手段，一是直接对原（训练）模型进行压缩，如通过剪枝（pruning）与量化（quantization）等技术。二是将原模型的“知识”进行“提炼”并“传授”给预部署的目标模型（另一类潜在场景即维护原模型与模型部署主体不同，而后者数据匮乏，无法进行有效训练）。本质上，第二种手段是通过建立在原模型与目标模型间的间接知识传递实现的，是谓“授之以渔”。实现该手段的技术方法的集合通常被称为知识蒸馏（knowledge distillation）。


关于知识蒸馏，几个核心问题包括：

- 知识蒸馏的基本框架是怎样的？
- 所传递的知识主要有哪些形式？
- 知识蒸馏的主要技术思想？

围绕上述问题，我们接下来将对知识蒸馏的基本元素展开介绍。
<br><br>

### 要素其一：基本架构

常见的知识蒸馏框架如下图所示。

| ![front image](/images/20220426fig3.png) |
|:--:|
| <b style="font-size:12px"> (Source from the Internet) </b>|

知识蒸馏包括“教师模型”（teacher model）和“学生模型”（student model）。前者是基于已有数据集完成训练的模型，后者是未训练或未完成训练的模型。在知识蒸馏过程中，教师模型首先采样小部分数据，结合数据通过某种蒸馏机制得到模型知识，接着将知识与采样数据一同传给学生模型。学生模型通过优化自身参数，在给定相同数据前提下，产生尽可能与该知识相匹配的输出。这边优化的性能指标一般有两类：一是尽可能与教师模型输出匹配，此类指标称为保真度（fidelity）；二是学生模型的泛化性能。两者都可以是直接优化目标的一部分，但需要注意的是，后者才是最终目标。

以上过程中，知识可以单向传递，也可引入闭环控制（学生通过提供反馈信息，让教师进一步优化蒸馏策略）。更一般地，蒸馏过程可有多个教师或多个学生同时参与，或二者兼有。这里不作讨论。
<br><br>

### 要素其二：知识形式

知识的形式是知识蒸馏的核心要素之一。其不仅决定了传递的信息量（进而影响学生的性能），同时也影响蒸馏方法的设计。暂抛开知识蒸馏，机器学习中两类常见的知识载体，一是数据，二是模型。前者可以由现实观测所得，或由模型合成。后者以数据为原料，被塑造为解决特定任务的工具。通过传递数据进行知识迁移不难理解。至于模型，例如，在联邦学习中，客户端周期性地将本地训练模型上传到服务器，并由后者完成模型聚合，得到全局模型。此过程便可视为知识传递的一类方式。然而，此例仅限于模型（参数）本身。更广义上讲，模型知识应定义为模型产物。其除了模型本身（所有参数），还可包含模型训练（如梯度更新）以及模型推理过程的产物。

![front image](/images/20220426fig4.png) 

知识蒸馏中，知识主要以模型推理的中间产物为载体。常见有三大类，分别是基于响应的知识（response-based knowledge）、基于特征的知识（feature-based knowledge）和基于关联的知识（relation-based knowledge）。下面我们对这三大类知识进行简要介绍。
<br><br>

- 基于响应的知识

基于响应的知识又被称为基于预测（prediction-based）或基于激活（activation-based）的知识。在监督学习中，其被定义为（前向）神经网络最终全连接层的输出。

![front image](/images/20220426fig5.png) 

比如，在面向多分类问题的神经网络中，响应定义为给定输入时，其推理产生的关于各类别评分的原始输出矢量。这些输出通常会经过正规化运算（如softmax）转化为有效的随机分布，以刻画该输入属于各类别的似然率。

值得指出的是，正规化运算可能造成有价值信息的损失。考虑上图中的例子。该例中，相较正规化处理前，关于第2类到第k类的评分差异性在正规化处理后显著降低。尽管这些差异的变化对此次推理的最后结果没有影响，然而它们却蕴含了该模型推理过程关于各类判断的重要信息，如哪些类相比其他类与该输入有着更大的相似性。这类信息通常被称为“暗知识”（dark knowledge），其编码了与模型泛化性相关的信息。这类信息作为模型推理的中间产物之一，被运用在基于响应的知识蒸馏（response-based knowledge distillation）中。

直观来说，教师在向学生传授知识时，提供数据样本后（类比习题集），相比仅告诉学生最终答案，进一步提供其对每个类（选项）的判断情况更有望给学生的泛化学习能力带来提升。
<br><br>




<script>
(function(){
        var elems = document.getElementsByClassName("view");
        elems[elems.length-1].remove();})();
</script>
{% if page.comments %}
    {% include disqus.html %}
{% endif %}